{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1hVDzX8dksOSVBZ_mWd7Gn6WcRM_RQDMn",
      "authorship_tag": "ABX9TyNjLfH0HuBQ8kiKJ4IaXa+N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SB24-28-48-ss/Face_Recogn_demo/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== ADVANCED FACE RECOGNITION ATTENDANCE SYSTEM =====================\n",
        "# Complete Colab-ready code with:\n",
        "# - RetinaFace detection, Face alignment, ArcFace embeddings\n",
        "# - Multi-classifier matching (KNN, FAISS, SVM)\n",
        "# - DeepSort tracking, Temporal voting, Quality filtering\n",
        "# - Image enhancement (CLAHE, Gamma, Denoising, Face-SR)\n",
        "\n",
        "# ===================== INSTALL DEPENDENCIES =====================\n",
        "# Run this cell first in Colab\n",
        "\n",
        "!pip install -q insightface onnxruntime-gpu faiss-gpu-cu11\n",
        "!pip install -q deep-sort-realtime\n",
        "!pip install -q opencv-python-headless\n",
        "!pip install -q scikit-learn pandas pytz\n",
        "!pip install -q gfpgan basicsr facexlib realesrgan\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# For face super-resolution models\n",
        "!pip install -q git+https://github.com/xinntao/GFPGAN.git\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# ===================== IMPORTS =====================\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import json\n",
        "import sqlite3\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from collections import defaultdict\n",
        "from typing import List, Tuple, Dict, Optional, Any\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML Libraries\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pytz\n",
        "\n",
        "# Deep Learning\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# InsightFace for RetinaFace + ArcFace\n",
        "import insightface\n",
        "from insightface.app import FaceAnalysis\n",
        "\n",
        "# FAISS for efficient similarity search\n",
        "import faiss\n",
        "\n",
        "# DeepSORT for tracking\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "\n",
        "# Face Enhancement\n",
        "try:\n",
        "    from gfpgan import GFPGANer\n",
        "    GFPGAN_AVAILABLE = True\n",
        "except ImportError:\n",
        "    GFPGAN_AVAILABLE = False\n",
        "    print(\"[WARNING] GFPGAN not available. Face-SR will be disabled.\")\n",
        "\n",
        "\n",
        "# ===================== CONFIGURATION =====================\n",
        "class Config:\n",
        "    \"\"\"Central configuration for the attendance system\"\"\"\n",
        "\n",
        "    # Paths (modify these for your Colab environment)\n",
        "    ENROLL_DIR = \"/content/drive/MyDrive/Photo\"\n",
        "    VIDEO_PATH = \"/content/drive/MyDrive/Video/classroom1.mp4\"\n",
        "    REPORT_PATH = \"/content/drive/MyDrive/attendance_report.csv\"\n",
        "    DEBUG_DIR = \"/content/drive/MyDrive/debug_faces\"\n",
        "    DB_PATH = \"/content/attendance.db\"\n",
        "    MODELS_DIR = \"/content/models\"\n",
        "\n",
        "    # Video Processing\n",
        "    FRAME_SKIP = 5  # Process every Nth frame\n",
        "    MAX_FRAMES = 3000  # Maximum frames to process\n",
        "\n",
        "    # Face Detection (RetinaFace)\n",
        "    DETECTION_SIZE = 640  # Input size for detector\n",
        "    DETECTION_THRESH = 0.5  # Detection confidence threshold\n",
        "\n",
        "    # Face Quality Thresholds\n",
        "    MIN_FACE_SIZE = 25  # Lowered to 30 to catch smaller faces (was 64)\n",
        "    MIN_BLUR_SCORE = 60.0  # Lowered to 60 to accept slightly blurrier small faces (was 100)\n",
        "    MAX_YAW_ANGLE = 45  # Maximum allowed yaw angle (side profile)\n",
        "    MAX_PITCH_ANGLE = 30  # Maximum allowed pitch angle\n",
        "    MAX_ROLL_ANGLE = 30  # Maximum allowed roll angle\n",
        "\n",
        "    # Face Matching Thresholds\n",
        "    COSINE_THRESHOLD = 0.40  # Minimum cosine similarity for match\n",
        "    MARGIN_THRESHOLD = 0.10  # Minimum margin vs second-best match\n",
        "\n",
        "    # Temporal Voting\n",
        "    VOTE_THRESHOLD = 3  # Minimum votes for confirmed identity\n",
        "    VOTE_WINDOW_FRAMES = 15  # Frames to consider for voting\n",
        "\n",
        "    # DeepSORT Tracking\n",
        "    MAX_AGE = 30  # Max frames to keep track without detection\n",
        "    N_INIT = 3  # Frames before track is confirmed\n",
        "    MAX_IOU_DISTANCE = 0.7\n",
        "\n",
        "    # Attendance\n",
        "    TIME_CUTOFF_MIN = 8  # Minutes between attendance marks\n",
        "    TIMEZONE = \"Asia/Kolkata\"\n",
        "\n",
        "    # Image Enhancement\n",
        "    ENABLE_CLAHE = True\n",
        "    ENABLE_GAMMA = True\n",
        "    ENABLE_DENOISE = False\n",
        "    ENABLE_SHARPENING = False  # Mild sharpening for clarity\n",
        "    ENABLE_FACE_SR = False  # Deep learning face super-resolution\n",
        "\n",
        "    # Debug\n",
        "    SAVE_DEBUG_FACES = True\n",
        "    SAVE_PREPROCESSING_STEPS = True  # Save before/after preprocessing images\n",
        "    PREPROCESSING_DEBUG_DIR = \"/content/drive/MyDrive/preprocessing_debug\"\n",
        "    VERBOSE = True\n",
        "\n",
        "\n",
        "# ===================== UTILITY FUNCTIONS =====================\n",
        "\n",
        "def create_directories():\n",
        "    \"\"\"Create necessary directories\"\"\"\n",
        "    os.makedirs(Config.DEBUG_DIR, exist_ok=True)\n",
        "    os.makedirs(Config.MODELS_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "def log(msg: str, level: str = \"INFO\"):\n",
        "    \"\"\"Logging utility\"\"\"\n",
        "    if Config.VERBOSE:\n",
        "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
        "        print(f\"[{timestamp}] [{level}] {msg}\")\n",
        "\n",
        "\n",
        "# ===================== DATABASE MANAGER =====================\n",
        "\n",
        "class DatabaseManager:\n",
        "    \"\"\"SQLite database for users, embeddings, and attendance\"\"\"\n",
        "\n",
        "    def __init__(self, db_path: str = Config.DB_PATH):\n",
        "        self.db_path = db_path\n",
        "\n",
        "    def init_db(self):\n",
        "        \"\"\"Initialize database schema\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        c = conn.cursor()\n",
        "\n",
        "        c.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS users (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                name TEXT UNIQUE,\n",
        "                threshold REAL DEFAULT 0.40\n",
        "            )\n",
        "        \"\"\")\n",
        "\n",
        "        c.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS embeddings (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                user_id INTEGER,\n",
        "                embedding BLOB,\n",
        "                quality_score REAL,\n",
        "                FOREIGN KEY (user_id) REFERENCES users(id)\n",
        "            )\n",
        "        \"\"\")\n",
        "\n",
        "        c.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS centroids (\n",
        "                user_id INTEGER,\n",
        "                centroid BLOB,\n",
        "                FOREIGN KEY (user_id) REFERENCES users(id)\n",
        "            )\n",
        "        \"\"\")\n",
        "\n",
        "        c.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS attendance (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                user_id INTEGER,\n",
        "                timestamp TEXT,\n",
        "                confidence REAL,\n",
        "                FOREIGN KEY (user_id) REFERENCES users(id)\n",
        "            )\n",
        "        \"\"\")\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "        log(\"Database initialized\")\n",
        "\n",
        "    def reset_db(self):\n",
        "        \"\"\"Reset database\"\"\"\n",
        "        if os.path.exists(self.db_path):\n",
        "            os.remove(self.db_path)\n",
        "        self.init_db()\n",
        "\n",
        "    def add_user(self, name: str) -> int:\n",
        "        \"\"\"Add a new user and return user_id\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"INSERT OR IGNORE INTO users (name) VALUES (?)\", (name,))\n",
        "        c.execute(\"SELECT id FROM users WHERE name = ?\", (name,))\n",
        "        uid = c.fetchone()[0]\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "        return uid\n",
        "\n",
        "    def add_embedding(self, user_id: int, embedding: np.ndarray, quality: float):\n",
        "        \"\"\"Store embedding for a user\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        c = conn.cursor()\n",
        "        emb_blob = embedding.astype(np.float32).tobytes()\n",
        "        c.execute(\n",
        "            \"INSERT INTO embeddings (user_id, embedding, quality_score) VALUES (?, ?, ?)\",\n",
        "            (user_id, emb_blob, quality)\n",
        "        )\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def add_centroid(self, user_id: int, centroid: np.ndarray):\n",
        "        \"\"\"Store centroid for a user\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        c = conn.cursor()\n",
        "        cent_blob = centroid.astype(np.float32).tobytes()\n",
        "        c.execute(\"INSERT INTO centroids (user_id, centroid) VALUES (?, ?)\",\n",
        "                  (user_id, cent_blob))\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def get_all_embeddings(self) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"Get all embeddings and their user_ids\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"SELECT user_id, embedding FROM embeddings\")\n",
        "        rows = c.fetchall()\n",
        "        conn.close()\n",
        "\n",
        "        if not rows:\n",
        "            return np.array([]), np.array([])\n",
        "\n",
        "        user_ids = np.array([r[0] for r in rows])\n",
        "        embeddings = np.array([np.frombuffer(r[1], dtype=np.float32) for r in rows])\n",
        "        return embeddings, user_ids\n",
        "\n",
        "    def get_all_centroids(self) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"Get all centroids and their user_ids\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"SELECT user_id, centroid FROM centroids\")\n",
        "        rows = c.fetchall()\n",
        "        conn.close()\n",
        "\n",
        "        if not rows:\n",
        "            return np.array([]), np.array([])\n",
        "\n",
        "        user_ids = np.array([r[0] for r in rows])\n",
        "        centroids = np.array([np.frombuffer(r[1], dtype=np.float32) for r in rows])\n",
        "        return centroids, user_ids\n",
        "\n",
        "    def get_users(self) -> Dict[int, str]:\n",
        "        \"\"\"Get mapping of user_id to name\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        df = pd.read_sql(\"SELECT id, name FROM users\", conn)\n",
        "        conn.close()\n",
        "        return dict(zip(df['id'], df['name']))\n",
        "\n",
        "    def get_user_threshold(self, user_id: int) -> float:\n",
        "        \"\"\"Get user's matching threshold\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"SELECT threshold FROM users WHERE id = ?\", (user_id,))\n",
        "        row = c.fetchone()\n",
        "        conn.close()\n",
        "        return row[0] if row else Config.COSINE_THRESHOLD\n",
        "\n",
        "    def mark_attendance(self, user_id: int, confidence: float) -> bool:\n",
        "        \"\"\"Mark attendance if not recently marked\"\"\"\n",
        "        tz = pytz.timezone(Config.TIMEZONE)\n",
        "        now = datetime.now(tz)\n",
        "\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        c = conn.cursor()\n",
        "\n",
        "        c.execute(\n",
        "            \"SELECT timestamp FROM attendance WHERE user_id = ? ORDER BY timestamp DESC LIMIT 1\",\n",
        "            (user_id,)\n",
        "        )\n",
        "        row = c.fetchone()\n",
        "\n",
        "        if row:\n",
        "            last_time = datetime.fromisoformat(row[0])\n",
        "            if now - last_time < timedelta(minutes=Config.TIME_CUTOFF_MIN):\n",
        "                conn.close()\n",
        "                return False\n",
        "\n",
        "        c.execute(\n",
        "            \"INSERT INTO attendance (user_id, timestamp, confidence) VALUES (?, ?, ?)\",\n",
        "            (user_id, now.isoformat(), confidence)\n",
        "        )\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "        return True\n",
        "\n",
        "    def export_attendance(self, output_path: str) -> pd.DataFrame:\n",
        "        \"\"\"Export attendance to CSV\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        df = pd.read_sql(\"\"\"\n",
        "            SELECT users.name, attendance.timestamp, attendance.confidence\n",
        "            FROM attendance\n",
        "            JOIN users ON attendance.user_id = users.id\n",
        "            ORDER BY attendance.timestamp\n",
        "        \"\"\", conn)\n",
        "        conn.close()\n",
        "        df.to_csv(output_path, index=False)\n",
        "        log(f\"Attendance exported to {output_path}\")\n",
        "        return df\n",
        "\n",
        "\n",
        "# ===================== IMAGE ENHANCEMENT =====================\n",
        "\n",
        "class ImageEnhancer:\n",
        "    \"\"\"Image preprocessing and enhancement pipeline\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.gfpgan = None\n",
        "        if Config.ENABLE_FACE_SR and GFPGAN_AVAILABLE:\n",
        "            self._init_gfpgan()\n",
        "\n",
        "    def _init_gfpgan(self):\n",
        "        \"\"\"Initialize GFPGAN for face super-resolution\"\"\"\n",
        "        try:\n",
        "            self.gfpgan = GFPGANer(\n",
        "                model_path='https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth',\n",
        "                upscale=2,\n",
        "                arch='clean',\n",
        "                channel_multiplier=2,\n",
        "                bg_upsampler=None\n",
        "            )\n",
        "            log(\"GFPGAN initialized for face super-resolution\")\n",
        "        except Exception as e:\n",
        "            log(f\"Failed to initialize GFPGAN: {e}\", \"WARNING\")\n",
        "            self.gfpgan = None\n",
        "\n",
        "    def apply_clahe(self, image: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Apply Contrast Limited Adaptive Histogram Equalization\"\"\"\n",
        "        if len(image.shape) == 3:\n",
        "            lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "            l, a, b = cv2.split(lab)\n",
        "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "            l = clahe.apply(l)\n",
        "            lab = cv2.merge([l, a, b])\n",
        "            return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
        "        else:\n",
        "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "            return clahe.apply(image)\n",
        "\n",
        "    def apply_gamma_correction(self, image: np.ndarray, gamma: float = 1.2) -> np.ndarray:\n",
        "        \"\"\"Apply gamma correction for brightness adjustment\"\"\"\n",
        "        inv_gamma = 1.0 / gamma\n",
        "        table = np.array([\n",
        "            ((i / 255.0) ** inv_gamma) * 255\n",
        "            for i in np.arange(0, 256)\n",
        "        ]).astype(\"uint8\")\n",
        "        return cv2.LUT(image, table)\n",
        "\n",
        "    def apply_denoising(self, image: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Apply Non-Local Means Denoising\"\"\"\n",
        "        if len(image.shape) == 3:\n",
        "            return cv2.fastNlMeansDenoisingColored(image, None, 6, 6, 7, 21)\n",
        "        else:\n",
        "            return cv2.fastNlMeansDenoising(image, None, 6, 7, 21)\n",
        "\n",
        "    def apply_sharpening(self, image: np.ndarray, strength: float = 0.3) -> np.ndarray:\n",
        "        \"\"\"Apply mild sharpening\"\"\"\n",
        "        kernel = np.array([[-1, -1, -1],\n",
        "                          [-1, 9 + strength, -1],\n",
        "                          [-1, -1, -1]]) / (1 + strength)\n",
        "        return cv2.filter2D(image, -1, kernel)\n",
        "\n",
        "    def apply_face_sr(self, face_image: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Apply deep learning based face super-resolution using GFPGAN\"\"\"\n",
        "        if self.gfpgan is None:\n",
        "            return face_image\n",
        "\n",
        "        try:\n",
        "            _, _, output = self.gfpgan.enhance(\n",
        "                face_image,\n",
        "                has_aligned=True,\n",
        "                only_center_face=False,\n",
        "                paste_back=False\n",
        "            )\n",
        "            if output is not None:\n",
        "                return output\n",
        "        except Exception as e:\n",
        "            log(f\"Face-SR failed: {e}\", \"WARNING\")\n",
        "\n",
        "        return face_image\n",
        "\n",
        "    def enhance_face(self, face_image: np.ndarray,\n",
        "                     apply_sr: bool = False,\n",
        "                     save_debug: bool = False,\n",
        "                     debug_prefix: str = \"face\") -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Full enhancement pipeline for a face crop.\n",
        "\n",
        "        Args:\n",
        "            face_image: Input face image (BGR)\n",
        "            apply_sr: Whether to apply Face Super-Resolution\n",
        "            save_debug: Whether to save preprocessing step images\n",
        "            debug_prefix: Prefix for debug image filenames\n",
        "        \"\"\"\n",
        "        enhanced = face_image.copy()\n",
        "        preprocessing_steps = {}\n",
        "\n",
        "        # Store original\n",
        "        preprocessing_steps['1_original'] = face_image.copy()\n",
        "\n",
        "        # Tier 1: Conservative enhancements\n",
        "        if Config.ENABLE_CLAHE:\n",
        "            enhanced = self.apply_clahe(enhanced)\n",
        "            preprocessing_steps['2_after_clahe'] = enhanced.copy()\n",
        "\n",
        "        if Config.ENABLE_GAMMA:\n",
        "            # Force Gamma on all faces (default 1.2 to brighten slightly)\n",
        "            gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)\n",
        "            mean_brightness = np.mean(gray)\n",
        "\n",
        "            gamma = 1.2  # Default to 1.2 for all faces as requested\n",
        "            if mean_brightness > 180:\n",
        "                gamma = 0.8  # Still darken extremely bright faces\n",
        "\n",
        "            enhanced = self.apply_gamma_correction(enhanced, gamma)\n",
        "            preprocessing_steps['3_after_gamma'] = enhanced.copy()\n",
        "\n",
        "        if Config.ENABLE_DENOISE:\n",
        "            enhanced = self.apply_denoising(enhanced)\n",
        "            preprocessing_steps['4_after_denoise'] = enhanced.copy()\n",
        "\n",
        "        # Apply mild sharpening for clarity\n",
        "        if Config.ENABLE_SHARPENING:\n",
        "            enhanced = self.apply_sharpening(enhanced, strength=0.3)\n",
        "            preprocessing_steps['5_after_sharpen'] = enhanced.copy()\n",
        "\n",
        "        # Tier 2: Deep learning enhancement (optional)\n",
        "        if apply_sr and Config.ENABLE_FACE_SR:\n",
        "            enhanced = self.apply_face_sr(enhanced)\n",
        "            preprocessing_steps['6_after_face_sr'] = enhanced.copy()\n",
        "\n",
        "        # Store final result\n",
        "        preprocessing_steps['7_final'] = enhanced.copy()\n",
        "\n",
        "        # Save preprocessing steps if enabled\n",
        "        if save_debug and Config.SAVE_PREPROCESSING_STEPS:\n",
        "            self._save_preprocessing_steps(preprocessing_steps, debug_prefix)\n",
        "\n",
        "        return enhanced\n",
        "\n",
        "    def _save_preprocessing_steps(self, steps: Dict[str, np.ndarray], prefix: str):\n",
        "        \"\"\"Save individual preprocessing step images and a combined comparison image\"\"\"\n",
        "        import os\n",
        "\n",
        "        # Create preprocessing debug directory\n",
        "        os.makedirs(Config.PREPROCESSING_DEBUG_DIR, exist_ok=True)\n",
        "\n",
        "        # Save individual step images\n",
        "        for step_name, img in steps.items():\n",
        "            path = os.path.join(Config.PREPROCESSING_DEBUG_DIR, f\"{prefix}_{step_name}.jpg\")\n",
        "            cv2.imwrite(path, img)\n",
        "\n",
        "        # Create combined comparison image (side-by-side)\n",
        "        step_images = list(steps.values())\n",
        "        step_names = list(steps.keys())\n",
        "\n",
        "        # Resize all to same size for comparison\n",
        "        target_size = (112, 112)\n",
        "        resized_images = []\n",
        "        for img in step_images:\n",
        "            resized = cv2.resize(img, target_size)\n",
        "            resized_images.append(resized)\n",
        "\n",
        "        # Create comparison grid (rows of 3)\n",
        "        rows = []\n",
        "        current_row = []\n",
        "        for img in resized_images:\n",
        "            current_row.append(img)\n",
        "            if len(current_row) == 3:\n",
        "                rows.append(np.hstack(current_row))\n",
        "                current_row = []\n",
        "\n",
        "        # Handle leftover in last row\n",
        "        if current_row:\n",
        "            while len(current_row) < 3:\n",
        "                current_row.append(np.zeros_like(resized_images[0]))\n",
        "            rows.append(np.hstack(current_row))\n",
        "\n",
        "        combined = np.vstack(rows)\n",
        "\n",
        "        # Add labels to the combined image\n",
        "        combined_labeled = self._add_step_labels(combined, step_names, target_size)\n",
        "\n",
        "        # Save combined comparison\n",
        "        comparison_path = os.path.join(Config.PREPROCESSING_DEBUG_DIR, f\"{prefix}_comparison.jpg\")\n",
        "        cv2.imwrite(comparison_path, combined_labeled)\n",
        "        log(f\"Saved preprocessing comparison: {comparison_path}\", \"DEBUG\")\n",
        "\n",
        "    def _add_step_labels(self, combined: np.ndarray, step_names: List[str],\n",
        "                         cell_size: Tuple[int, int]) -> np.ndarray:\n",
        "        \"\"\"Add text labels to the combined comparison image\"\"\"\n",
        "        h, w = combined.shape[:2]\n",
        "        cell_w, cell_h = cell_size\n",
        "\n",
        "        # Create a taller image to add labels at bottom of each cell\n",
        "        label_height = 25\n",
        "        n_rows = (len(step_names) + 2) // 3  # Number of rows\n",
        "        labeled = np.zeros((h + label_height * n_rows, w, 3), dtype=np.uint8)\n",
        "\n",
        "        # Copy the combined image\n",
        "        for row in range(n_rows):\n",
        "            y_offset = row * (cell_h + label_height)\n",
        "            y_src = row * cell_h\n",
        "            labeled[y_offset:y_offset + cell_h, :] = combined[y_src:y_src + cell_h, :]\n",
        "\n",
        "        # Add labels\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        font_scale = 0.35\n",
        "        for i, name in enumerate(step_names):\n",
        "            row = i // 3\n",
        "            col = i % 3\n",
        "            x = col * cell_w + 5\n",
        "            y = row * (cell_h + label_height) + cell_h + 18\n",
        "\n",
        "            # Clean up name for display\n",
        "            display_name = name.replace('_', ' ').split(' ', 1)[-1].upper()\n",
        "            cv2.putText(labeled, display_name, (x, y), font, font_scale, (255, 255, 255), 1)\n",
        "\n",
        "        return labeled\n",
        "\n",
        "    def enhance_frame(self, frame: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Light enhancement for full frame (before detection)\"\"\"\n",
        "        enhanced = frame.copy()\n",
        "\n",
        "        if Config.ENABLE_CLAHE:\n",
        "            enhanced = self.apply_clahe(enhanced)\n",
        "\n",
        "        return enhanced\n",
        "\n",
        "\n",
        "# ===================== FACE QUALITY ASSESSMENT =====================\n",
        "\n",
        "class FaceQualityAssessor:\n",
        "    \"\"\"Assess face quality for filtering bad detections\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_blur_score(face_image: np.ndarray) -> float:\n",
        "        \"\"\"Compute Laplacian variance as blur metric (higher = sharper)\"\"\"\n",
        "        gray = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n",
        "        return cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "\n",
        "    @staticmethod\n",
        "    def check_face_size(bbox: Tuple[int, int, int, int]) -> bool:\n",
        "        \"\"\"Check if face meets minimum size requirement\"\"\"\n",
        "        x1, y1, x2, y2 = bbox\n",
        "        w, h = x2 - x1, y2 - y1\n",
        "        return w >= Config.MIN_FACE_SIZE and h >= Config.MIN_FACE_SIZE\n",
        "\n",
        "    @staticmethod\n",
        "    def check_face_pose(landmarks: np.ndarray) -> Tuple[bool, Dict[str, float]]:\n",
        "        \"\"\"\n",
        "        Check face pose angles from landmarks.\n",
        "        Returns (is_acceptable, angles_dict)\n",
        "        \"\"\"\n",
        "        if landmarks is None or len(landmarks) < 5:\n",
        "            return True, {}  # Can't assess, assume OK\n",
        "\n",
        "        # 5-point landmarks: left_eye, right_eye, nose, left_mouth, right_mouth\n",
        "        left_eye = landmarks[0]\n",
        "        right_eye = landmarks[1]\n",
        "        nose = landmarks[2]\n",
        "\n",
        "        # Estimate yaw from eye positions relative to nose\n",
        "        eye_center = (left_eye + right_eye) / 2\n",
        "        eye_dist = np.linalg.norm(right_eye - left_eye)\n",
        "\n",
        "        if eye_dist < 1:\n",
        "            return True, {}\n",
        "\n",
        "        # Rough yaw estimation\n",
        "        nose_offset = (nose[0] - eye_center[0]) / eye_dist\n",
        "        yaw = np.arctan(nose_offset) * 180 / np.pi * 2\n",
        "\n",
        "        # Rough pitch estimation\n",
        "        eye_nose_dist = nose[1] - eye_center[1]\n",
        "        pitch = (eye_nose_dist / eye_dist - 0.5) * 60\n",
        "\n",
        "        # Roll estimation from eye angle\n",
        "        roll = np.arctan2(right_eye[1] - left_eye[1],\n",
        "                         right_eye[0] - left_eye[0]) * 180 / np.pi\n",
        "\n",
        "        angles = {'yaw': abs(yaw), 'pitch': abs(pitch), 'roll': abs(roll)}\n",
        "\n",
        "        is_acceptable = (\n",
        "            abs(yaw) <= Config.MAX_YAW_ANGLE and\n",
        "            abs(pitch) <= Config.MAX_PITCH_ANGLE and\n",
        "            abs(roll) <= Config.MAX_ROLL_ANGLE\n",
        "        )\n",
        "\n",
        "        return is_acceptable, angles\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_quality_score(face_image: np.ndarray,\n",
        "                             landmarks: np.ndarray = None) -> float:\n",
        "        \"\"\"Compute overall quality score (0-100)\"\"\"\n",
        "        scores = []\n",
        "\n",
        "        # Blur score (normalize to 0-100)\n",
        "        blur = FaceQualityAssessor.compute_blur_score(face_image)\n",
        "        blur_score = min(100, blur / 5)  # 500+ variance = 100\n",
        "        scores.append(blur_score)\n",
        "\n",
        "        # Size score\n",
        "        h, w = face_image.shape[:2]\n",
        "        size_score = min(100, (min(w, h) / 112) * 100)\n",
        "        scores.append(size_score)\n",
        "\n",
        "        # Pose score\n",
        "        if landmarks is not None:\n",
        "            is_ok, angles = FaceQualityAssessor.check_face_pose(landmarks)\n",
        "            if angles:\n",
        "                pose_score = 100 - (angles['yaw'] + angles['pitch'] + angles['roll']) / 3\n",
        "                pose_score = max(0, pose_score)\n",
        "                scores.append(pose_score)\n",
        "\n",
        "        return np.mean(scores)\n",
        "\n",
        "    @staticmethod\n",
        "    def filter_face(bbox: Tuple[int, int, int, int],\n",
        "                   face_image: np.ndarray,\n",
        "                   landmarks: np.ndarray = None) -> Tuple[bool, str]:\n",
        "        \"\"\"\n",
        "        Check if face passes quality filters.\n",
        "        Returns (passes, reason)\n",
        "        \"\"\"\n",
        "        # Size check\n",
        "        if not FaceQualityAssessor.check_face_size(bbox):\n",
        "            return False, \"too_small\"\n",
        "\n",
        "        # Blur check\n",
        "        blur_score = FaceQualityAssessor.compute_blur_score(face_image)\n",
        "        if blur_score < Config.MIN_BLUR_SCORE:\n",
        "            return False, f\"too_blurry ({blur_score:.1f})\"\n",
        "\n",
        "        # Pose check\n",
        "        if landmarks is not None:\n",
        "            is_ok, angles = FaceQualityAssessor.check_face_pose(landmarks)\n",
        "            if not is_ok:\n",
        "                return False, f\"bad_pose (yaw={angles.get('yaw', 0):.1f})\"\n",
        "\n",
        "        return True, \"ok\"\n",
        "\n",
        "\n",
        "# ===================== FACE DETECTOR & RECOGNIZER =====================\n",
        "\n",
        "class FaceProcessor:\n",
        "    \"\"\"RetinaFace detection + ArcFace embedding extraction\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.app = None\n",
        "        self._init_insightface()\n",
        "        self.enhancer = ImageEnhancer()\n",
        "        self.quality_assessor = FaceQualityAssessor()\n",
        "\n",
        "    def _init_insightface(self):\n",
        "        \"\"\"Initialize InsightFace with RetinaFace detector + ArcFace recognizer\"\"\"\n",
        "        self.app = FaceAnalysis(\n",
        "            name='buffalo_l',  # Includes RetinaFace + ArcFace\n",
        "            providers=['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
        "        )\n",
        "        self.app.prepare(ctx_id=0, det_size=(Config.DETECTION_SIZE, Config.DETECTION_SIZE))\n",
        "        log(\"InsightFace initialized (RetinaFace + ArcFace)\")\n",
        "\n",
        "    def detect_faces(self, frame: np.ndarray, apply_full_enhancement: bool = True) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Detect faces in frame with quality filtering and full enhancement pipeline.\n",
        "        Returns list of face dicts with bbox, landmarks, embedding, quality.\n",
        "\n",
        "        Args:\n",
        "            frame: Input BGR frame\n",
        "            apply_full_enhancement: If True, apply full face enhancement (CLAHE, gamma,\n",
        "                                   denoising, Face-SR) to each face crop before embedding\n",
        "        \"\"\"\n",
        "        # Enhance frame before detection (light enhancement)\n",
        "        enhanced_frame = self.enhancer.enhance_frame(frame)\n",
        "\n",
        "        # Run detection\n",
        "        faces = self.app.get(enhanced_frame)\n",
        "\n",
        "        results = []\n",
        "        for face in faces:\n",
        "            bbox = face.bbox.astype(int)\n",
        "            x1, y1, x2, y2 = bbox\n",
        "\n",
        "            # Validate bbox\n",
        "            x1, y1 = max(0, x1), max(0, y1)\n",
        "            x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)\n",
        "\n",
        "            if x2 <= x1 or y2 <= y1:\n",
        "                continue\n",
        "\n",
        "            # Extract face crop from ORIGINAL frame (not enhanced)\n",
        "            face_crop = frame[y1:y2, x1:x2].copy()\n",
        "            if face_crop.size == 0:\n",
        "                continue\n",
        "\n",
        "            # Quality filtering BEFORE enhancement\n",
        "            landmarks = face.kps if hasattr(face, 'kps') else None\n",
        "            passes, reason = self.quality_assessor.filter_face(\n",
        "                (x1, y1, x2, y2), face_crop, landmarks\n",
        "            )\n",
        "\n",
        "            if not passes:\n",
        "                log(f\"Face rejected: {reason}\", \"DEBUG\")\n",
        "                continue\n",
        "\n",
        "            # ========== FULL FACE PREPROCESSING PIPELINE ==========\n",
        "            if apply_full_enhancement:\n",
        "                # Step 1: Face Alignment using landmarks\n",
        "                aligned_face = self.align_face(frame, landmarks, target_size=112)\n",
        "\n",
        "                if aligned_face is not None:\n",
        "                    # Use aligned face for processing\n",
        "                    face_to_enhance = aligned_face\n",
        "                    log(f\"Face aligned using 5-point landmarks\", \"DEBUG\")\n",
        "                else:\n",
        "                    # Fallback: resize face crop if alignment fails\n",
        "                    face_to_enhance = cv2.resize(face_crop, (112, 112))\n",
        "                    log(f\"Alignment failed, using resized crop\", \"DEBUG\")\n",
        "\n",
        "                # Step 2: Apply Tier 1 Enhancement: CLAHE, Gamma Correction, Denoising\n",
        "                # Step 3: Apply Tier 2 Enhancement: Face Super-Resolution (GFPGAN) for small faces\n",
        "                apply_sr = (face_crop.shape[0] < 96 or face_crop.shape[1] < 96)\n",
        "\n",
        "                # Save preprocessing debug for first N faces (to avoid too many files)\n",
        "                self._face_debug_counter = getattr(self, '_face_debug_counter', 0) + 1\n",
        "                save_this_debug = (self._face_debug_counter <= 20)  # Save first 20 faces\n",
        "                debug_prefix = f\"face_{self._face_debug_counter:04d}\"\n",
        "\n",
        "                enhanced_face = self.enhancer.enhance_face(\n",
        "                    face_to_enhance,\n",
        "                    apply_sr=apply_sr,\n",
        "                    save_debug=save_this_debug,\n",
        "                    debug_prefix=debug_prefix\n",
        "                )\n",
        "\n",
        "                # Step 4: Re-extract embedding from enhanced & aligned face\n",
        "                new_embedding = self.extract_embedding_from_crop(enhanced_face, apply_enhancement=False)\n",
        "\n",
        "                if new_embedding is not None:\n",
        "                    embedding = new_embedding\n",
        "                else:\n",
        "                    # Fallback to original embedding if re-detection/extraction fails\n",
        "                    log(\"Re-extraction failed on enhanced face, using original embedding\", \"DEBUG\")\n",
        "                    embedding = face.embedding\n",
        "                    if embedding is not None:\n",
        "                        embedding = embedding / np.linalg.norm(embedding)\n",
        "\n",
        "                # Store enhanced face for debug/visualization\n",
        "                face_crop_final = enhanced_face\n",
        "            else:\n",
        "                # Use original InsightFace embedding (no enhancement)\n",
        "                embedding = face.embedding\n",
        "                if embedding is not None:\n",
        "                    embedding = embedding / np.linalg.norm(embedding)\n",
        "                face_crop_final = face_crop\n",
        "\n",
        "            # Compute quality score\n",
        "            quality = self.quality_assessor.compute_quality_score(face_crop, landmarks)\n",
        "\n",
        "            results.append({\n",
        "                'bbox': (x1, y1, x2, y2),\n",
        "                'landmarks': landmarks,\n",
        "                'embedding': embedding,\n",
        "                'quality': quality,\n",
        "                'face_crop': face_crop_final,\n",
        "                'face_crop_original': face_crop,  # Keep original for reference\n",
        "                'det_score': face.det_score,\n",
        "                'enhanced': apply_full_enhancement,\n",
        "                'aligned': apply_full_enhancement and aligned_face is not None\n",
        "            })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def align_face(self, frame: np.ndarray, landmarks: np.ndarray,\n",
        "                   target_size: int = 112) -> np.ndarray:\n",
        "        \"\"\"Align face using 5-point landmarks\"\"\"\n",
        "        if landmarks is None or len(landmarks) < 5:\n",
        "            return None\n",
        "\n",
        "        # Standard alignment targets for 112x112\n",
        "        src_pts = np.array([\n",
        "            [38.2946, 51.6963],\n",
        "            [73.5318, 51.5014],\n",
        "            [56.0252, 71.7366],\n",
        "            [41.5493, 92.3655],\n",
        "            [70.7299, 92.2041]\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "        dst_pts = landmarks[:5].astype(np.float32)\n",
        "\n",
        "        # Compute similarity transform\n",
        "        tform = cv2.estimateAffinePartial2D(dst_pts, src_pts)[0]\n",
        "        if tform is None:\n",
        "            return None\n",
        "\n",
        "        aligned = cv2.warpAffine(frame, tform, (target_size, target_size))\n",
        "        return aligned\n",
        "\n",
        "    def extract_embedding_from_crop(self, face_crop: np.ndarray,\n",
        "                                    apply_enhancement: bool = True) -> np.ndarray:\n",
        "        \"\"\"Extract embedding from a face crop\"\"\"\n",
        "        if apply_enhancement:\n",
        "            face_crop = self.enhancer.enhance_face(face_crop, apply_sr=True)\n",
        "\n",
        "        # Resize to expected input size\n",
        "        face_resized = cv2.resize(face_crop, (112, 112))\n",
        "\n",
        "        # Get embedding\n",
        "        faces = self.app.get(face_resized)\n",
        "        if len(faces) == 0:\n",
        "            return None\n",
        "\n",
        "        embedding = faces[0].embedding\n",
        "        return embedding / np.linalg.norm(embedding)\n",
        "\n",
        "\n",
        "# ===================== MULTI-CLASSIFIER MATCHER =====================\n",
        "\n",
        "class MultiClassifierMatcher:\n",
        "    \"\"\"Ensemble of KNN, FAISS, and SVM for robust matching\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.knn = None\n",
        "        self.svm = None\n",
        "        self.faiss_index = None\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.user_ids = None\n",
        "        self.embeddings = None\n",
        "\n",
        "    def build(self, embeddings: np.ndarray, user_ids: np.ndarray):\n",
        "        \"\"\"Build all classifiers from enrollment embeddings\"\"\"\n",
        "        if len(embeddings) == 0:\n",
        "            log(\"No embeddings to build classifiers\", \"WARNING\")\n",
        "            return\n",
        "\n",
        "        self.embeddings = embeddings.astype(np.float32)\n",
        "        self.user_ids = user_ids\n",
        "\n",
        "        # Encode labels\n",
        "        self.label_encoder.fit(user_ids)\n",
        "        encoded_labels = self.label_encoder.transform(user_ids)\n",
        "\n",
        "        # Build KNN\n",
        "        n_neighbors = min(5, len(embeddings))\n",
        "        self.knn = KNeighborsClassifier(n_neighbors=n_neighbors, metric='cosine')\n",
        "        self.knn.fit(embeddings, user_ids)\n",
        "        log(f\"KNN built with k={n_neighbors}\")\n",
        "\n",
        "        # Build SVM\n",
        "        if len(np.unique(user_ids)) >= 2:\n",
        "            self.svm = SVC(kernel='rbf', probability=True, C=10)\n",
        "            self.svm.fit(embeddings, user_ids)\n",
        "            log(\"SVM built\")\n",
        "\n",
        "        # Build FAISS index\n",
        "        dim = embeddings.shape[1]\n",
        "        self.faiss_index = faiss.IndexFlatIP(dim)  # Inner product (cosine for normalized)\n",
        "        faiss.normalize_L2(self.embeddings)\n",
        "        self.faiss_index.add(self.embeddings)\n",
        "        log(f\"FAISS index built with {len(embeddings)} embeddings\")\n",
        "\n",
        "    def match_faiss(self, embedding: np.ndarray, top_k: int = 5) -> List[Tuple[int, float]]:\n",
        "        \"\"\"Match using FAISS, returns [(user_id, similarity), ...]\"\"\"\n",
        "        if self.faiss_index is None:\n",
        "            return []\n",
        "\n",
        "        query = embedding.reshape(1, -1).astype(np.float32)\n",
        "        faiss.normalize_L2(query)\n",
        "\n",
        "        similarities, indices = self.faiss_index.search(query, top_k)\n",
        "\n",
        "        results = []\n",
        "        for sim, idx in zip(similarities[0], indices[0]):\n",
        "            if idx >= 0:\n",
        "                results.append((int(self.user_ids[idx]), float(sim)))\n",
        "\n",
        "        return results\n",
        "\n",
        "    def match_knn(self, embedding: np.ndarray) -> Tuple[int, np.ndarray]:\n",
        "        \"\"\"Match using KNN, returns (predicted_user_id, probabilities)\"\"\"\n",
        "        if self.knn is None:\n",
        "            return -1, np.array([])\n",
        "\n",
        "        pred = self.knn.predict(embedding.reshape(1, -1))[0]\n",
        "        probs = self.knn.predict_proba(embedding.reshape(1, -1))[0]\n",
        "        return int(pred), probs\n",
        "\n",
        "    def match_svm(self, embedding: np.ndarray) -> Tuple[int, np.ndarray]:\n",
        "        \"\"\"Match using SVM, returns (predicted_user_id, probabilities)\"\"\"\n",
        "        if self.svm is None:\n",
        "            return -1, np.array([])\n",
        "\n",
        "        pred = self.svm.predict(embedding.reshape(1, -1))[0]\n",
        "        probs = self.svm.predict_proba(embedding.reshape(1, -1))[0]\n",
        "        return int(pred), probs\n",
        "\n",
        "    def ensemble_match(self, embedding: np.ndarray,\n",
        "                      centroids: np.ndarray = None,\n",
        "                      centroid_ids: np.ndarray = None) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Ensemble matching using all classifiers.\n",
        "        Returns detailed match result.\n",
        "        \"\"\"\n",
        "        result = {\n",
        "            'matched': False,\n",
        "            'user_id': -1,\n",
        "            'confidence': 0.0,\n",
        "            'margin': 0.0,\n",
        "            'details': {}\n",
        "        }\n",
        "\n",
        "        # FAISS matching\n",
        "        faiss_matches = self.match_faiss(embedding, top_k=5)\n",
        "        if faiss_matches:\n",
        "            result['details']['faiss'] = {\n",
        "                'top_id': faiss_matches[0][0],\n",
        "                'top_sim': faiss_matches[0][1],\n",
        "                'second_sim': faiss_matches[1][1] if len(faiss_matches) > 1 else 0\n",
        "            }\n",
        "\n",
        "        # KNN matching\n",
        "        knn_pred, knn_probs = self.match_knn(embedding)\n",
        "        if knn_pred != -1:\n",
        "            result['details']['knn'] = {\n",
        "                'pred_id': knn_pred,\n",
        "                'max_prob': float(np.max(knn_probs)) if len(knn_probs) > 0 else 0\n",
        "            }\n",
        "\n",
        "        # SVM matching\n",
        "        svm_pred, svm_probs = self.match_svm(embedding)\n",
        "        if svm_pred != -1:\n",
        "            result['details']['svm'] = {\n",
        "                'pred_id': svm_pred,\n",
        "                'max_prob': float(np.max(svm_probs)) if len(svm_probs) > 0 else 0\n",
        "            }\n",
        "\n",
        "        # Centroid matching (if available)\n",
        "        if centroids is not None and len(centroids) > 0:\n",
        "            similarities = np.dot(centroids, embedding)\n",
        "            best_idx = np.argmax(similarities)\n",
        "            second_idx = np.argsort(similarities)[-2] if len(similarities) > 1 else best_idx\n",
        "\n",
        "            result['details']['centroid'] = {\n",
        "                'best_id': int(centroid_ids[best_idx]),\n",
        "                'best_sim': float(similarities[best_idx]),\n",
        "                'second_sim': float(similarities[second_idx]),\n",
        "                'margin': float(similarities[best_idx] - similarities[second_idx])\n",
        "            }\n",
        "\n",
        "        # Voting logic\n",
        "        votes = defaultdict(float)\n",
        "\n",
        "        if 'faiss' in result['details']:\n",
        "            d = result['details']['faiss']\n",
        "            votes[d['top_id']] += d['top_sim']\n",
        "\n",
        "        if 'knn' in result['details']:\n",
        "            d = result['details']['knn']\n",
        "            votes[d['pred_id']] += d['max_prob']\n",
        "\n",
        "        if 'svm' in result['details']:\n",
        "            d = result['details']['svm']\n",
        "            votes[d['pred_id']] += d['max_prob']\n",
        "\n",
        "        if 'centroid' in result['details']:\n",
        "            d = result['details']['centroid']\n",
        "            votes[d['best_id']] += d['best_sim']\n",
        "\n",
        "        if votes:\n",
        "            best_user = max(votes, key=votes.get)\n",
        "            best_score = votes[best_user]\n",
        "            sorted_votes = sorted(votes.values(), reverse=True)\n",
        "            margin = sorted_votes[0] - sorted_votes[1] if len(sorted_votes) > 1 else sorted_votes[0]\n",
        "\n",
        "            # Final decision\n",
        "            if best_score >= Config.COSINE_THRESHOLD and margin >= Config.MARGIN_THRESHOLD:\n",
        "                result['matched'] = True\n",
        "                result['user_id'] = best_user\n",
        "                result['confidence'] = best_score / 4  # Normalize by number of classifiers\n",
        "                result['margin'] = margin\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "# ===================== TRACKER MANAGER =====================\n",
        "\n",
        "class TrackerManager:\n",
        "    \"\"\"Manage face tracking with DeepSORT\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.tracker = DeepSort(\n",
        "            max_age=Config.MAX_AGE,\n",
        "            n_init=Config.N_INIT,\n",
        "            max_iou_distance=Config.MAX_IOU_DISTANCE\n",
        "        )\n",
        "        self.track_embeddings = defaultdict(list)  # track_id -> [embeddings]\n",
        "        self.track_votes = defaultdict(lambda: defaultdict(int))  # track_id -> {user_id: count}\n",
        "        self.confirmed_tracks = set()  # track_ids that have been matched\n",
        "\n",
        "    def update(self, detections: List[Dict], frame: np.ndarray) -> List[Tuple[int, Dict]]:\n",
        "        \"\"\"\n",
        "        Update tracker with new detections.\n",
        "        Returns list of (track_id, face_info) for active tracks.\n",
        "        \"\"\"\n",
        "        if not detections:\n",
        "            self.tracker.update_tracks([], frame=frame)\n",
        "            return []\n",
        "\n",
        "        # Format detections for DeepSORT: [[x1, y1, x2, y2, conf], ...]\n",
        "        bbox_xyxy = []\n",
        "        confidences = []\n",
        "        embeddings_list = []\n",
        "\n",
        "        for det in detections:\n",
        "            x1, y1, x2, y2 = det['bbox']\n",
        "            bbox_xyxy.append([x1, y1, x2, y2])\n",
        "            confidences.append(det['det_score'])\n",
        "            embeddings_list.append(det['embedding'])\n",
        "\n",
        "        # Update tracker\n",
        "        tracks = self.tracker.update_tracks(\n",
        "            list(zip(bbox_xyxy, confidences)),\n",
        "            frame=frame,\n",
        "            embeds=embeddings_list if embeddings_list else None\n",
        "        )\n",
        "\n",
        "        # Process active tracks\n",
        "        results = []\n",
        "        for track in tracks:\n",
        "            if not track.is_confirmed():\n",
        "                continue\n",
        "\n",
        "            track_id = track.track_id\n",
        "            bbox = track.to_ltrb()\n",
        "\n",
        "            # Find corresponding detection\n",
        "            best_det = None\n",
        "            best_iou = 0\n",
        "            for det in detections:\n",
        "                iou = self._compute_iou(bbox, det['bbox'])\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "                    best_det = det\n",
        "\n",
        "            if best_det is not None and best_det['embedding'] is not None:\n",
        "                self.track_embeddings[track_id].append(best_det['embedding'])\n",
        "                # Keep only recent embeddings\n",
        "                if len(self.track_embeddings[track_id]) > Config.VOTE_WINDOW_FRAMES:\n",
        "                    self.track_embeddings[track_id] = self.track_embeddings[track_id][-Config.VOTE_WINDOW_FRAMES:]\n",
        "\n",
        "                results.append((track_id, best_det))\n",
        "\n",
        "        return results\n",
        "\n",
        "    def vote_identity(self, track_id: int, user_id: int):\n",
        "        \"\"\"Register a vote for identity\"\"\"\n",
        "        self.track_votes[track_id][user_id] += 1\n",
        "\n",
        "    def get_confirmed_identity(self, track_id: int) -> Optional[int]:\n",
        "        \"\"\"Get confirmed identity for track if votes exceed threshold\"\"\"\n",
        "        if track_id in self.confirmed_tracks:\n",
        "            # Already confirmed, return the highest voted\n",
        "            votes = self.track_votes[track_id]\n",
        "            if votes:\n",
        "                return max(votes, key=votes.get)\n",
        "            return None\n",
        "\n",
        "        votes = self.track_votes[track_id]\n",
        "        if votes:\n",
        "            best_user = max(votes, key=votes.get)\n",
        "            if votes[best_user] >= Config.VOTE_THRESHOLD:\n",
        "                self.confirmed_tracks.add(track_id)\n",
        "                return best_user\n",
        "        return None\n",
        "\n",
        "    def get_aggregated_embedding(self, track_id: int) -> Optional[np.ndarray]:\n",
        "        \"\"\"Get average embedding for a track\"\"\"\n",
        "        if track_id not in self.track_embeddings:\n",
        "            return None\n",
        "\n",
        "        embeddings = self.track_embeddings[track_id]\n",
        "        if not embeddings:\n",
        "            return None\n",
        "\n",
        "        avg_emb = np.mean(embeddings, axis=0)\n",
        "        return avg_emb / np.linalg.norm(avg_emb)\n",
        "\n",
        "    def _compute_iou(self, box1: Tuple, box2: Tuple) -> float:\n",
        "        \"\"\"Compute IoU between two boxes\"\"\"\n",
        "        x1 = max(box1[0], box2[0])\n",
        "        y1 = max(box1[1], box2[1])\n",
        "        x2 = min(box1[2], box2[2])\n",
        "        y2 = min(box1[3], box2[3])\n",
        "\n",
        "        inter = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "        union = area1 + area2 - inter\n",
        "\n",
        "        return inter / union if union > 0 else 0\n",
        "\n",
        "\n",
        "# ===================== ENROLLMENT PIPELINE =====================\n",
        "\n",
        "def run_enrollment(config: Config = Config):\n",
        "    \"\"\"Enroll users from image directory\"\"\"\n",
        "    log(\"Starting enrollment process...\")\n",
        "\n",
        "    db = DatabaseManager(config.DB_PATH)\n",
        "    db.reset_db()\n",
        "\n",
        "    face_processor = FaceProcessor()\n",
        "\n",
        "    enrolled_count = 0\n",
        "\n",
        "    for person_name in sorted(os.listdir(config.ENROLL_DIR)):\n",
        "        person_dir = os.path.join(config.ENROLL_DIR, person_name)\n",
        "        if not os.path.isdir(person_dir):\n",
        "            continue\n",
        "\n",
        "        user_id = db.add_user(person_name)\n",
        "        person_embeddings = []\n",
        "\n",
        "        for img_file in os.listdir(person_dir):\n",
        "            img_path = os.path.join(person_dir, img_file)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Detect and process faces\n",
        "            faces = face_processor.detect_faces(img)\n",
        "\n",
        "            if len(faces) == 0:\n",
        "                log(f\"No face detected in {img_file}\", \"WARNING\")\n",
        "                continue\n",
        "\n",
        "            # Use best quality face\n",
        "            best_face = max(faces, key=lambda x: x['quality'])\n",
        "\n",
        "            if best_face['embedding'] is not None:\n",
        "                db.add_embedding(user_id, best_face['embedding'], best_face['quality'])\n",
        "                person_embeddings.append(best_face['embedding'])\n",
        "                log(f\"Enrolled {person_name}/{img_file} (quality: {best_face['quality']:.1f})\")\n",
        "\n",
        "        if person_embeddings:\n",
        "            enrolled_count += 1\n",
        "            log(f\"Enrolled {person_name} with {len(person_embeddings)} images\")\n",
        "\n",
        "    log(f\"Enrollment complete: {enrolled_count} users\")\n",
        "    return db\n",
        "\n",
        "\n",
        "def build_models(db: DatabaseManager):\n",
        "    \"\"\"Build classification models from enrolled embeddings\"\"\"\n",
        "    log(\"Building classification models...\")\n",
        "\n",
        "    embeddings, user_ids = db.get_all_embeddings()\n",
        "\n",
        "    if len(embeddings) == 0:\n",
        "        log(\"No embeddings found!\", \"ERROR\")\n",
        "        return None\n",
        "\n",
        "    # Build centroids using K-Means\n",
        "    for uid in np.unique(user_ids):\n",
        "        user_embs = embeddings[user_ids == uid]\n",
        "\n",
        "        if len(user_embs) <= 2:\n",
        "            centroid = user_embs.mean(axis=0)\n",
        "            centroid = centroid / np.linalg.norm(centroid)\n",
        "            db.add_centroid(int(uid), centroid)\n",
        "        else:\n",
        "            n_clusters = min(3, len(user_embs))\n",
        "            kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "            kmeans.fit(user_embs)\n",
        "\n",
        "            for center in kmeans.cluster_centers_:\n",
        "                center = center / np.linalg.norm(center)\n",
        "                db.add_centroid(int(uid), center)\n",
        "\n",
        "    # Build multi-classifier\n",
        "    matcher = MultiClassifierMatcher()\n",
        "    matcher.build(embeddings, user_ids)\n",
        "\n",
        "    # Save matcher\n",
        "    pickle.dump(matcher, open(os.path.join(Config.MODELS_DIR, \"matcher.pkl\"), \"wb\"))\n",
        "    log(\"Models built and saved\")\n",
        "\n",
        "    return matcher\n",
        "\n",
        "\n",
        "# ===================== RECOGNITION PIPELINE =====================\n",
        "\n",
        "def run_recognition(config: Config = Config):\n",
        "    \"\"\"Run face recognition on video\"\"\"\n",
        "    log(\"Starting recognition process...\")\n",
        "\n",
        "    # Load components\n",
        "    db = DatabaseManager(config.DB_PATH)\n",
        "    face_processor = FaceProcessor()\n",
        "    tracker = TrackerManager()\n",
        "\n",
        "    matcher = pickle.load(open(os.path.join(Config.MODELS_DIR, \"matcher.pkl\"), \"rb\"))\n",
        "    centroids, centroid_ids = db.get_all_centroids()\n",
        "    id2name = db.get_users()\n",
        "\n",
        "    # Open video\n",
        "    cap = cv2.VideoCapture(config.VIDEO_PATH)\n",
        "    if not cap.isOpened():\n",
        "        log(f\"Failed to open video: {config.VIDEO_PATH}\", \"ERROR\")\n",
        "        return\n",
        "\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    log(f\"Video: {total_frames} frames @ {fps:.1f} FPS ({frame_width}x{frame_height})\")\n",
        "\n",
        "    # Create output video writer for annotated frames\n",
        "    annotated_video_path = os.path.join(config.DEBUG_DIR, \"annotated_output.mp4\")\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'avc1')\n",
        "    out_video = cv2.VideoWriter(annotated_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "    log(f\"Annotated video will be saved to: {annotated_video_path}\")\n",
        "\n",
        "    # Storage for frame annotations\n",
        "    frame_annotations = {}  # frame_idx -> list of (bbox, name, confidence)\n",
        "\n",
        "    marked_users = set()\n",
        "    frame_idx = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "        if frame_idx > config.MAX_FRAMES:\n",
        "            break\n",
        "\n",
        "        if frame_idx % config.FRAME_SKIP != 0:\n",
        "            continue\n",
        "\n",
        "        # Detect faces\n",
        "        detections = face_processor.detect_faces(frame)\n",
        "\n",
        "        if not detections:\n",
        "            tracker.update([], frame)\n",
        "            continue\n",
        "\n",
        "        # ========== GATE 1: DeepSORT TRACKING ==========\n",
        "        # Update tracker with face detections\n",
        "        tracked_faces = tracker.update(detections, frame)\n",
        "\n",
        "        for track_id, face_info in tracked_faces:\n",
        "            # Skip if already confirmed and marked\n",
        "            confirmed_id = tracker.get_confirmed_identity(track_id)\n",
        "            if confirmed_id is not None and confirmed_id in marked_users:\n",
        "                continue\n",
        "\n",
        "            # ========== GATE 2: VERIFY EMBEDDING EXISTS ==========\n",
        "            # (Safe Gateway already filtered bad faces in detect_faces)\n",
        "            embedding = face_info['embedding']\n",
        "            if embedding is None:\n",
        "                log(f\"Track {track_id}: No embedding (Safe Gateway rejected)\", \"DEBUG\")\n",
        "                continue\n",
        "\n",
        "            # ========== GATE 3: MULTI-CLASSIFIER ENSEMBLE (KNN + FAISS + SVM) ==========\n",
        "            match_result = matcher.ensemble_match(embedding, centroids, centroid_ids)\n",
        "\n",
        "            # Log ensemble details\n",
        "            if config.VERBOSE:\n",
        "                details = match_result['details']\n",
        "                log(f\"Track {track_id} Ensemble Results:\", \"DEBUG\")\n",
        "                if 'faiss' in details:\n",
        "                    log(f\"  FAISS: user={details['faiss']['top_id']} sim={details['faiss']['top_sim']:.3f}\", \"DEBUG\")\n",
        "                if 'knn' in details:\n",
        "                    log(f\"  KNN: user={details['knn']['pred_id']} prob={details['knn']['max_prob']:.3f}\", \"DEBUG\")\n",
        "                if 'svm' in details:\n",
        "                    log(f\"  SVM: user={details['svm']['pred_id']} prob={details['svm']['max_prob']:.3f}\", \"DEBUG\")\n",
        "                if 'centroid' in details:\n",
        "                    log(f\"  Centroid: user={details['centroid']['best_id']} sim={details['centroid']['best_sim']:.3f}\", \"DEBUG\")\n",
        "\n",
        "            # ========== GATE 4: ENSEMBLE THRESHOLD CHECK ==========\n",
        "            if not match_result['matched']:\n",
        "                log(f\"Track {track_id}: Ensemble match failed (threshold not met)\", \"DEBUG\")\n",
        "                continue\n",
        "\n",
        "            user_id = match_result['user_id']\n",
        "            confidence = match_result['confidence']\n",
        "            user_name = id2name.get(user_id, f\"Unknown-{user_id}\")\n",
        "\n",
        "            # ========== GATE 4.5: PER-USER THRESHOLD CHECK ==========\n",
        "            # Use per-user threshold from database for individual tuning\n",
        "            user_threshold = db.get_user_threshold(user_id)\n",
        "            if confidence < user_threshold:\n",
        "                log(f\"Track {track_id}: {user_name} - confidence {confidence:.3f} below user threshold {user_threshold:.3f}\", \"DEBUG\")\n",
        "                continue\n",
        "\n",
        "            log(f\"Track {track_id}: Ensemble PASSED  {user_name} (conf={confidence:.2f}, margin={match_result['margin']:.2f}, user_thr={user_threshold:.2f})\", \"DEBUG\")\n",
        "\n",
        "            # ========== GATE 5: TEMPORAL VOTING ==========\n",
        "            # Register vote for this identity on this track\n",
        "            tracker.vote_identity(track_id, user_id)\n",
        "            vote_count = tracker.track_votes[track_id][user_id]\n",
        "\n",
        "            log(f\"Track {track_id}: Vote registered for {user_name} (votes={vote_count}/{Config.VOTE_THRESHOLD})\", \"DEBUG\")\n",
        "\n",
        "            # ========== GATE 5.5: AGGREGATED EMBEDDING VERIFICATION ==========\n",
        "            # Use aggregated embedding from multiple frames for more robust matching\n",
        "            aggregated_emb = tracker.get_aggregated_embedding(track_id)\n",
        "            if aggregated_emb is not None and vote_count >= 2:\n",
        "                # Re-verify with aggregated embedding for extra confidence\n",
        "                agg_match = matcher.ensemble_match(aggregated_emb, centroids, centroid_ids)\n",
        "                if agg_match['matched'] and agg_match['user_id'] == user_id:\n",
        "                    log(f\"Track {track_id}: Aggregated embedding CONFIRMED {user_name} (agg_conf={agg_match['confidence']:.2f})\", \"DEBUG\")\n",
        "                elif agg_match['matched'] and agg_match['user_id'] != user_id:\n",
        "                    log(f\"Track {track_id}: Aggregated embedding MISMATCH! Frame says {user_name}, aggregated says {id2name.get(agg_match['user_id'], 'Unknown')}\", \"WARNING\")\n",
        "                    continue  # Skip if aggregated embedding disagrees\n",
        "\n",
        "            # Store annotation for this frame\n",
        "            if frame_idx not in frame_annotations:\n",
        "                frame_annotations[frame_idx] = []\n",
        "            frame_annotations[frame_idx].append({\n",
        "                'bbox': face_info['bbox'],\n",
        "                'name': user_name,\n",
        "                'confidence': confidence,\n",
        "                'confirmed': False\n",
        "            })\n",
        "\n",
        "            # ========== GATE 6: TEMPORAL CONFIRMATION (3+ frames) ==========\n",
        "            confirmed_id = tracker.get_confirmed_identity(track_id)\n",
        "\n",
        "            if confirmed_id is None:\n",
        "                log(f\"Track {track_id}: Awaiting temporal confirmation ({vote_count}/{Config.VOTE_THRESHOLD} votes)\", \"DEBUG\")\n",
        "                continue\n",
        "\n",
        "            # ========== GATE 7: FINAL ATTENDANCE MARKING ==========\n",
        "            if confirmed_id not in marked_users:\n",
        "                confirmed_name = id2name.get(confirmed_id, f\"Unknown-{confirmed_id}\")\n",
        "\n",
        "                # Mark attendance in database\n",
        "                if db.mark_attendance(confirmed_id, confidence):\n",
        "                    marked_users.add(confirmed_id)\n",
        "\n",
        "                    # Update annotation as confirmed\n",
        "                    if frame_annotations.get(frame_idx):\n",
        "                        frame_annotations[frame_idx][-1]['confirmed'] = True\n",
        "                        frame_annotations[frame_idx][-1]['name'] = confirmed_name\n",
        "\n",
        "                    # Log successful attendance with all gates passed\n",
        "                    log(f\"[ATTENDANCE MARKED] {confirmed_name}\", \"INFO\")\n",
        "                    log(f\"   Gate 1: Safe Gateway (quality filter) - PASSED\", \"INFO\")\n",
        "                    log(f\"   Gate 2: DeepSORT Tracking (track_id={track_id}) - PASSED\", \"INFO\")\n",
        "                    log(f\"   Gate 3: KNN+FAISS+SVM Ensemble (conf={confidence:.2f}) - PASSED\", \"INFO\")\n",
        "                    log(f\"   Gate 4: Temporal Voting ({vote_count} votes) - PASSED\", \"INFO\")\n",
        "                    log(f\"   Gate 5: Time Cutoff Check - PASSED\", \"INFO\")\n",
        "\n",
        "                    # ========== SAVE ANNOTATED FRAME (FULL FRAME WITH BOX + NAME) ==========\n",
        "                    if config.SAVE_DEBUG_FACES:\n",
        "                        # Draw bounding box and name on frame\n",
        "                        annotated_frame = frame.copy()\n",
        "                        x1, y1, x2, y2 = face_info['bbox']\n",
        "\n",
        "                        # Green box for confirmed attendance\n",
        "                        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "                        # Add name label with background\n",
        "                        label = f\"{confirmed_name} ({confidence:.2f})\"\n",
        "                        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "                        font_scale = 0.8\n",
        "                        thickness = 2\n",
        "                        (text_w, text_h), baseline = cv2.getTextSize(label, font, font_scale, thickness)\n",
        "\n",
        "                        # Draw label background\n",
        "                        cv2.rectangle(annotated_frame, (x1, y1 - text_h - 10), (x1 + text_w + 10, y1), (0, 255, 0), -1)\n",
        "                        cv2.putText(annotated_frame, label, (x1 + 5, y1 - 5), font, font_scale, (0, 0, 0), thickness)\n",
        "\n",
        "                        # Save annotated full frame\n",
        "                        frame_path = os.path.join(\n",
        "                            config.DEBUG_DIR,\n",
        "                            f\"frame_{frame_idx}_{confirmed_name}_MARKED.jpg\"\n",
        "                        )\n",
        "                        cv2.imwrite(frame_path, annotated_frame)\n",
        "                        log(f\"   Saved annotated frame: {frame_path}\", \"INFO\")\n",
        "\n",
        "                        # Also save the face crop\n",
        "                        crop_path = os.path.join(\n",
        "                            config.DEBUG_DIR,\n",
        "                            f\"face_{frame_idx}_{confirmed_name}.jpg\"\n",
        "                        )\n",
        "                        cv2.imwrite(crop_path, face_info['face_crop'])\n",
        "                else:\n",
        "                    log(f\"Track {track_id}: {confirmed_name} already marked recently (time cutoff)\", \"DEBUG\")\n",
        "\n",
        "        # ========== DRAW ALL DETECTIONS ON FRAME FOR VIDEO ==========\n",
        "        annotated_frame = frame.copy()\n",
        "        for det in detections:\n",
        "            x1, y1, x2, y2 = det['bbox']\n",
        "            # Yellow box for all detections\n",
        "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
        "\n",
        "        # Draw confirmed identities in green\n",
        "        if frame_idx in frame_annotations:\n",
        "            for ann in frame_annotations[frame_idx]:\n",
        "                x1, y1, x2, y2 = ann['bbox']\n",
        "                if ann['confirmed']:\n",
        "                    color = (0, 255, 0)  # Green for confirmed\n",
        "                else:\n",
        "                    color = (255, 165, 0)  # Orange for matched but not confirmed\n",
        "\n",
        "                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 3)\n",
        "                label = f\"{ann['name']} ({ann['confidence']:.2f})\"\n",
        "                cv2.putText(annotated_frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "        # Write annotated frame to video\n",
        "        out_video.write(annotated_frame)\n",
        "\n",
        "        # Progress\n",
        "        if frame_idx % 100 == 0:\n",
        "            log(f\"Processed {frame_idx}/{min(total_frames, config.MAX_FRAMES)} frames\")\n",
        "\n",
        "    cap.release()\n",
        "    out_video.release()\n",
        "    log(f\"Recognition complete. Marked {len(marked_users)} attendees.\")\n",
        "    log(f\"Annotated video saved to: {annotated_video_path}\")\n",
        "\n",
        "\n",
        "# ===================== VISUALIZATION =====================\n",
        "\n",
        "def visualize_embeddings(db: DatabaseManager):\n",
        "    \"\"\"Visualize enrollment embeddings using PCA\"\"\"\n",
        "    from sklearn.decomposition import PCA\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    embeddings, user_ids = db.get_all_embeddings()\n",
        "    id2name = db.get_users()\n",
        "\n",
        "    if len(embeddings) < 2:\n",
        "        log(\"Not enough embeddings for visualization\", \"WARNING\")\n",
        "        return\n",
        "\n",
        "    pca = PCA(n_components=2)\n",
        "    X_2d = pca.fit_transform(embeddings)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    for uid in np.unique(user_ids):\n",
        "        mask = user_ids == uid\n",
        "        name = id2name.get(uid, f\"User-{uid}\")\n",
        "        plt.scatter(X_2d[mask, 0], X_2d[mask, 1], label=name, s=100, alpha=0.7)\n",
        "\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.title(\"Enrollment Embeddings (PCA Projection)\")\n",
        "    plt.xlabel(\"PC1\")\n",
        "    plt.ylabel(\"PC2\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(Config.DEBUG_DIR, \"embedding_clusters.png\"), dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    log(\"Embedding visualization saved\")\n",
        "\n",
        "\n",
        "def visualize_attendance_timeline(db: DatabaseManager):\n",
        "    \"\"\"Visualize attendance over time\"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    conn = sqlite3.connect(db.db_path)\n",
        "    df = pd.read_sql(\"\"\"\n",
        "        SELECT users.name, attendance.timestamp, attendance.confidence\n",
        "        FROM attendance\n",
        "        JOIN users ON attendance.user_id = users.id\n",
        "    \"\"\", conn)\n",
        "    conn.close()\n",
        "\n",
        "    if df.empty:\n",
        "        log(\"No attendance records to visualize\", \"WARNING\")\n",
        "        return\n",
        "\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    for name in df['name'].unique():\n",
        "        person_df = df[df['name'] == name]\n",
        "        plt.scatter(person_df['timestamp'], [name] * len(person_df),\n",
        "                   s=person_df['confidence'] * 100, alpha=0.7, label=name)\n",
        "\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Person\")\n",
        "    plt.title(\"Attendance Timeline\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(Config.DEBUG_DIR, \"attendance_timeline.png\"), dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ===================== MAIN EXECUTION =====================\n",
        "\n",
        "def print_pipeline_info():\n",
        "    \"\"\"Print information about all classes and components used in the pipeline\"\"\"\n",
        "    print(\"\"\"\n",
        "\n",
        "           ADVANCED FACE RECOGNITION ATTENDANCE SYSTEM - PIPELINE             \n",
        "\n",
        "                                                                              \n",
        "  CLASSES USED:                                                               \n",
        "                                                                 \n",
        "  1. Config              - Central configuration parameters                   \n",
        "  2. DatabaseManager     - SQLite DB for users, embeddings, attendance        \n",
        "  3. ImageEnhancer       - CLAHE, Gamma, Denoising, GFPGAN Face-SR           \n",
        "  4. FaceQualityAssessor - Size/Blur/Pose filtering (<64px rejected)         \n",
        "  5. FaceProcessor       - RetinaFace detection + ArcFace embeddings         \n",
        "  6. MultiClassifierMatcher - KNN + FAISS + SVM ensemble                     \n",
        "  7. TrackerManager      - DeepSORT multi-object tracking                    \n",
        "                                                                              \n",
        "  PIPELINE FLOW:                                                              \n",
        "                                                                \n",
        "  ENROLLMENT:                                                                 \n",
        "    Images  FaceProcessor.detect_faces()                                    \n",
        "            ImageEnhancer.enhance_frame() [CLAHE on frame]                  \n",
        "            FaceQualityAssessor.filter_face() [reject bad faces]            \n",
        "            ImageEnhancer.enhance_face() [full Tier1+Tier2]                 \n",
        "            FaceProcessor.align_face() [landmark alignment]                 \n",
        "            ArcFace embedding extraction                                    \n",
        "            DatabaseManager.add_embedding()                                 \n",
        "                                                                              \n",
        "  MODEL BUILDING:                                                             \n",
        "    Embeddings  K-Means centroids                                           \n",
        "               MultiClassifierMatcher.build() [KNN+FAISS+SVM]               \n",
        "                                                                              \n",
        "  RECOGNITION:                                                                \n",
        "    Video  FaceProcessor.detect_faces() [with full enhancement]             \n",
        "          TrackerManager.update() [DeepSORT tracking]                       \n",
        "          MultiClassifierMatcher.ensemble_match()                           \n",
        "          TrackerManager.vote_identity() [temporal voting]                  \n",
        "          TrackerManager.get_confirmed_identity() [3+ frame votes]          \n",
        "          DatabaseManager.mark_attendance()                                 \n",
        "                                                                              \n",
        "\n",
        "    \"\"\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution pipeline.\n",
        "\n",
        "    This function orchestrates all components:\n",
        "    - Config: Configuration parameters\n",
        "    - DatabaseManager: User/embedding/attendance storage\n",
        "    - ImageEnhancer: Face preprocessing (CLAHE, Gamma, Denoise, Face-SR)\n",
        "    - FaceQualityAssessor: Quality filtering (size, blur, pose)\n",
        "    - FaceProcessor: RetinaFace detection + ArcFace embeddings + Face alignment\n",
        "    - MultiClassifierMatcher: KNN + FAISS + SVM ensemble matching\n",
        "    - TrackerManager: DeepSORT tracking + temporal voting\n",
        "    \"\"\"\n",
        "    log(\"=\" * 60)\n",
        "    log(\"ADVANCED FACE RECOGNITION ATTENDANCE SYSTEM\")\n",
        "    log(\"=\" * 60)\n",
        "\n",
        "    # Print pipeline information\n",
        "    print_pipeline_info()\n",
        "\n",
        "    # Create directories\n",
        "    create_directories()\n",
        "\n",
        "    # ==================== STEP 1: ENROLLMENT ====================\n",
        "    # Uses: Config, DatabaseManager, FaceProcessor\n",
        "    #       FaceProcessor internally uses: ImageEnhancer, FaceQualityAssessor\n",
        "    log(\"\\n[STEP 1] ENROLLMENT\")\n",
        "    log(\"   Using: DatabaseManager, FaceProcessor, ImageEnhancer, FaceQualityAssessor\")\n",
        "    db = run_enrollment()\n",
        "\n",
        "    # ==================== STEP 2: BUILD MODELS ====================\n",
        "    # Uses: DatabaseManager, MultiClassifierMatcher (KNN, FAISS, SVM), KMeans\n",
        "    log(\"\\n[STEP 2] BUILDING MODELS\")\n",
        "    log(\"   Using: MultiClassifierMatcher (KNN + FAISS + SVM), KMeans for centroids\")\n",
        "    matcher = build_models(db)\n",
        "\n",
        "    if matcher is None:\n",
        "        log(\"Failed to build models. Exiting.\", \"ERROR\")\n",
        "        return\n",
        "\n",
        "    # ==================== STEP 3: VISUALIZE EMBEDDINGS ====================\n",
        "    # Uses: DatabaseManager, PCA, matplotlib\n",
        "    log(\"\\n[STEP 3] VISUALIZING EMBEDDINGS\")\n",
        "    log(\"   Using: PCA for dimensionality reduction\")\n",
        "    visualize_embeddings(db)\n",
        "\n",
        "    # ==================== STEP 4: RECOGNITION ====================\n",
        "    # Uses: Config, DatabaseManager, FaceProcessor, TrackerManager, MultiClassifierMatcher\n",
        "    #       FaceProcessor uses: ImageEnhancer, FaceQualityAssessor\n",
        "    #       TrackerManager uses: DeepSORT\n",
        "    log(\"\\n[STEP 4] RUNNING RECOGNITION\")\n",
        "    log(\"   Using: FaceProcessor, TrackerManager (DeepSORT), MultiClassifierMatcher\")\n",
        "    log(\"   Enhancement: ImageEnhancer (CLAHE, Gamma, Denoise, Face-SR)\")\n",
        "    log(\"   Quality Filter: FaceQualityAssessor (min 64px, blur check, pose check)\")\n",
        "    log(\"   Temporal: Majority voting over 3+ frames\")\n",
        "    run_recognition()\n",
        "\n",
        "    # ==================== STEP 5: EXPORT RESULTS ====================\n",
        "    # Uses: DatabaseManager\n",
        "    log(\"\\n[STEP 5] EXPORTING RESULTS\")\n",
        "    log(\"   Using: DatabaseManager.export_attendance()\")\n",
        "    attendance_df = db.export_attendance(Config.REPORT_PATH)\n",
        "    print(\"\\n--- ATTENDANCE REPORT ---\")\n",
        "    print(attendance_df)\n",
        "\n",
        "    # ==================== STEP 6: VISUALIZE TIMELINE ====================\n",
        "    # Uses: DatabaseManager, matplotlib\n",
        "    log(\"\\n[STEP 6] VISUALIZING TIMELINE\")\n",
        "    log(\"   Using: matplotlib for timeline visualization\")\n",
        "    visualize_attendance_timeline(db)\n",
        "\n",
        "    # ==================== SUMMARY ====================\n",
        "    log(\"\\n\" + \"=\" * 60)\n",
        "    log(\"PIPELINE COMPLETE!\")\n",
        "    log(\"=\" * 60)\n",
        "\n",
        "    # Print summary of all classes used\n",
        "    print(\"\"\"\n",
        "    \n",
        "                        CLASSES SUMMARY                         \n",
        "    \n",
        "       Config               - Configuration loaded             \n",
        "       DatabaseManager      - DB initialized & populated       \n",
        "       ImageEnhancer        - Face enhancement applied         \n",
        "       FaceQualityAssessor  - Quality filtering active         \n",
        "       FaceProcessor        - RetinaFace + ArcFace used        \n",
        "       MultiClassifierMatcher - KNN/FAISS/SVM ensemble         \n",
        "       TrackerManager       - DeepSORT tracking + voting       \n",
        "    \n",
        "    \"\"\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WAzlCIEME_2S",
        "outputId": "82e835da-dbf1-4bad-85be-158766be4240"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[WARNING] GFPGAN not available. Face-SR will be disabled.\n",
            "[16:15:47] [INFO] ============================================================\n",
            "[16:15:47] [INFO] ADVANCED FACE RECOGNITION ATTENDANCE SYSTEM\n",
            "[16:15:47] [INFO] ============================================================\n",
            "\n",
            "\n",
            "           ADVANCED FACE RECOGNITION ATTENDANCE SYSTEM - PIPELINE             \n",
            "\n",
            "                                                                              \n",
            "  CLASSES USED:                                                               \n",
            "                                                                 \n",
            "  1. Config              - Central configuration parameters                   \n",
            "  2. DatabaseManager     - SQLite DB for users, embeddings, attendance        \n",
            "  3. ImageEnhancer       - CLAHE, Gamma, Denoising, GFPGAN Face-SR           \n",
            "  4. FaceQualityAssessor - Size/Blur/Pose filtering (<64px rejected)         \n",
            "  5. FaceProcessor       - RetinaFace detection + ArcFace embeddings         \n",
            "  6. MultiClassifierMatcher - KNN + FAISS + SVM ensemble                     \n",
            "  7. TrackerManager      - DeepSORT multi-object tracking                    \n",
            "                                                                              \n",
            "  PIPELINE FLOW:                                                              \n",
            "                                                                \n",
            "  ENROLLMENT:                                                                 \n",
            "    Images  FaceProcessor.detect_faces()                                    \n",
            "            ImageEnhancer.enhance_frame() [CLAHE on frame]                  \n",
            "            FaceQualityAssessor.filter_face() [reject bad faces]            \n",
            "            ImageEnhancer.enhance_face() [full Tier1+Tier2]                 \n",
            "            FaceProcessor.align_face() [landmark alignment]                 \n",
            "            ArcFace embedding extraction                                    \n",
            "            DatabaseManager.add_embedding()                                 \n",
            "                                                                              \n",
            "  MODEL BUILDING:                                                             \n",
            "    Embeddings  K-Means centroids                                           \n",
            "               MultiClassifierMatcher.build() [KNN+FAISS+SVM]               \n",
            "                                                                              \n",
            "  RECOGNITION:                                                                \n",
            "    Video  FaceProcessor.detect_faces() [with full enhancement]             \n",
            "          TrackerManager.update() [DeepSORT tracking]                       \n",
            "          MultiClassifierMatcher.ensemble_match()                           \n",
            "          TrackerManager.vote_identity() [temporal voting]                  \n",
            "          TrackerManager.get_confirmed_identity() [3+ frame votes]          \n",
            "          DatabaseManager.mark_attendance()                                 \n",
            "                                                                              \n",
            "\n",
            "    \n",
            "[16:15:47] [INFO] \n",
            "[STEP 1] ENROLLMENT\n",
            "[16:15:47] [INFO]    Using: DatabaseManager, FaceProcessor, ImageEnhancer, FaceQualityAssessor\n",
            "[16:15:47] [INFO] Starting enrollment process...\n",
            "[16:15:47] [INFO] Database initialized\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n",
            "[16:15:47] [INFO] InsightFace initialized (RetinaFace + ArcFace)\n",
            "[16:15:50] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:15:50] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0001_comparison.jpg\n",
            "[16:15:50] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:15:50] [INFO] Enrolled PDV/IMG-20250924-WA0047.jpg (quality: 99.3)\n",
            "[16:15:51] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:15:51] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0002_comparison.jpg\n",
            "[16:15:51] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:15:51] [INFO] Enrolled PDV/IMG-20250924-WA0048.jpg (quality: 83.7)\n",
            "[16:15:51] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:15:51] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0003_comparison.jpg\n",
            "[16:15:51] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:15:51] [INFO] Enrolled PDV/IMG-20250924-WA0045.jpg (quality: 98.7)\n",
            "[16:15:52] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:15:52] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0004_comparison.jpg\n",
            "[16:15:52] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:15:52] [INFO] Enrolled PDV/IMG-20250924-WA0049.jpg (quality: 98.7)\n",
            "[16:15:52] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:15:52] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0005_comparison.jpg\n",
            "[16:15:52] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:15:52] [INFO] Enrolled PDV/IMG-20250924-WA0041.jpg (quality: 90.5)\n",
            "[16:15:52] [INFO] Enrolled PDV with 5 images\n",
            "[16:15:53] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:15:53] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0006_comparison.jpg\n",
            "[16:15:53] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:15:53] [INFO] Enrolled RC/IMG-20250924-WA0044.jpg (quality: 79.0)\n",
            "[16:15:54] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:15:54] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0007_comparison.jpg\n",
            "[16:15:54] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:15:54] [INFO] Enrolled RC/IMG-20250924-WA0038.jpg (quality: 75.5)\n",
            "[16:15:54] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:15:54] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0008_comparison.jpg\n",
            "[16:15:54] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:15:54] [INFO] Enrolled RC/IMG-20250924-WA0040.jpg (quality: 72.4)\n",
            "[16:15:55] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:15:55] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0009_comparison.jpg\n",
            "[16:15:55] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:15:55] [INFO] Enrolled RC/IMG-20250924-WA0036.jpg (quality: 74.4)\n",
            "[16:15:55] [INFO] Enrolled RC with 4 images\n",
            "[16:15:56] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:15:56] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0010_comparison.jpg\n",
            "[16:15:56] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:15:56] [INFO] Enrolled SS/IMG-20250924-WA0046.jpg (quality: 71.8)\n",
            "[16:15:56] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:15:56] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0011_comparison.jpg\n",
            "[16:15:56] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:15:56] [INFO] Enrolled SS/IMG-20250924-WA0042.jpg (quality: 83.0)\n",
            "[16:15:57] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:15:57] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0012_comparison.jpg\n",
            "[16:15:57] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:15:57] [INFO] Enrolled SS/IMG-20250924-WA0023.jpg (quality: 79.2)\n",
            "[16:15:57] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:15:57] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0013_comparison.jpg\n",
            "[16:15:57] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:15:57] [INFO] Enrolled SS/IMG-20250924-WA0025.jpg (quality: 78.7)\n",
            "[16:15:58] [DEBUG] Face rejected: too_blurry (3.9)\n",
            "[16:15:58] [WARNING] No face detected in IMG_20250924_220007107.jpg\n",
            "[16:15:58] [DEBUG] Face rejected: too_blurry (3.7)\n",
            "[16:15:58] [WARNING] No face detected in IMG_20250924_220000833.jpg\n",
            "[16:15:59] [DEBUG] Face rejected: too_blurry (4.1)\n",
            "[16:15:59] [WARNING] No face detected in IMG_20250924_215953666.jpg\n",
            "[16:15:59] [DEBUG] Face rejected: too_blurry (3.7)\n",
            "[16:15:59] [WARNING] No face detected in IMG_20250924_215948611.jpg\n",
            "[16:15:59] [INFO] Enrolled SS with 4 images\n",
            "[16:16:00] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:16:00] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0014_comparison.jpg\n",
            "[16:16:00] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:16:00] [INFO] Enrolled TR/IMG_20250919_141949679.jpg (quality: 70.7)\n",
            "[16:16:00] [DEBUG] Face rejected: too_blurry (50.7)\n",
            "[16:16:00] [WARNING] No face detected in IMG_20250919_141946887.jpg\n",
            "[16:16:01] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:16:01] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0015_comparison.jpg\n",
            "[16:16:01] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:16:01] [INFO] Enrolled TR/IMG_20250918_130831213.jpg (quality: 71.1)\n",
            "[16:16:01] [INFO] Enrolled TR with 2 images\n",
            "[16:16:01] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:16:01] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0016_comparison.jpg\n",
            "[16:16:01] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:16:01] [INFO] Enrolled USB/IMG_20250918_130853765.jpg (quality: 76.2)\n",
            "[16:16:02] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:16:02] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0017_comparison.jpg\n",
            "[16:16:02] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:16:02] [INFO] Enrolled USB/IMG_20250918_130851378.jpg (quality: 77.5)\n",
            "[16:16:02] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:16:02] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0018_comparison.jpg\n",
            "[16:16:02] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:16:02] [INFO] Enrolled USB/IMG_20250919_142127799.jpg (quality: 71.9)\n",
            "[16:16:03] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:16:03] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0019_comparison.jpg\n",
            "[16:16:03] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:16:03] [INFO] Enrolled USB/IMG_20250919_142125769.jpg (quality: 72.9)\n",
            "[16:16:03] [DEBUG] Face aligned using 5-point landmarks\n",
            "[16:16:03] [DEBUG] Saved preprocessing comparison: /content/drive/MyDrive/preprocessing_debug/face_0020_comparison.jpg\n",
            "[16:16:03] [DEBUG] Re-extraction failed on enhanced face, using original embedding\n",
            "[16:16:03] [INFO] Enrolled USB/IMG_20250919_142117379.jpg (quality: 71.2)\n",
            "[16:16:03] [INFO] Enrolled USB with 5 images\n",
            "[16:16:03] [INFO] Enrollment complete: 5 users\n",
            "[16:16:04] [INFO] \n",
            "[STEP 2] BUILDING MODELS\n",
            "[16:16:04] [INFO]    Using: MultiClassifierMatcher (KNN + FAISS + SVM), KMeans for centroids\n",
            "[16:16:04] [INFO] Building classification models...\n",
            "[16:16:04] [INFO] KNN built with k=5\n",
            "[16:16:04] [INFO] SVM built\n",
            "[16:16:04] [INFO] FAISS index built with 20 embeddings\n",
            "[16:16:04] [INFO] Models built and saved\n",
            "[16:16:04] [INFO] \n",
            "[STEP 3] VISUALIZING EMBEDDINGS\n",
            "[16:16:04] [INFO]    Using: PCA for dimensionality reduction\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16:16:04] [INFO] Embedding visualization saved\n",
            "[16:16:04] [INFO] \n",
            "[STEP 4] RUNNING RECOGNITION\n",
            "[16:16:04] [INFO]    Using: FaceProcessor, TrackerManager (DeepSORT), MultiClassifierMatcher\n",
            "[16:16:04] [INFO]    Enhancement: ImageEnhancer (CLAHE, Gamma, Denoise, Face-SR)\n",
            "[16:16:04] [INFO]    Quality Filter: FaceQualityAssessor (min 64px, blur check, pose check)\n",
            "[16:16:04] [INFO]    Temporal: Majority voting over 3+ frames\n",
            "[16:16:04] [INFO] Starting recognition process...\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n",
            "[16:16:05] [INFO] InsightFace initialized (RetinaFace + ArcFace)\n",
            "[16:16:06] [INFO] Video: 758 frames @ 60.0 FPS (848x478)\n",
            "[16:16:06] [INFO] Annotated video will be saved to: /content/drive/MyDrive/debug_faces/annotated_output.mp4\n",
            "[16:16:09] [DEBUG] Face rejected: too_small\n",
            "[16:16:09] [DEBUG] Face rejected: too_small\n",
            "[16:16:09] [DEBUG] Face rejected: too_small\n",
            "[16:16:09] [DEBUG] Face rejected: too_small\n",
            "[16:16:09] [DEBUG] Face rejected: too_small\n",
            "[16:16:09] [DEBUG] Face rejected: too_small\n",
            "[16:16:09] [DEBUG] Face rejected: too_small\n",
            "[16:16:09] [DEBUG] Face rejected: too_small\n",
            "[16:16:09] [DEBUG] Face rejected: too_small\n",
            "[16:16:09] [DEBUG] Face rejected: too_small\n",
            "[16:16:09] [DEBUG] Face rejected: too_small\n",
            "[16:16:09] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:10] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:11] [DEBUG] Face rejected: too_small\n",
            "[16:16:12] [DEBUG] Face rejected: too_small\n",
            "[16:16:12] [DEBUG] Face rejected: too_small\n",
            "[16:16:12] [DEBUG] Face rejected: too_small\n",
            "[16:16:12] [DEBUG] Face rejected: too_small\n",
            "[16:16:12] [DEBUG] Face rejected: too_small\n",
            "[16:16:12] [DEBUG] Face rejected: too_small\n",
            "[16:16:12] [DEBUG] Face rejected: too_small\n",
            "[16:16:12] [DEBUG] Face rejected: too_small\n",
            "[16:16:12] [DEBUG] Face rejected: too_small\n",
            "[16:16:12] [DEBUG] Face rejected: too_small\n",
            "[16:16:12] [DEBUG] Face rejected: too_small\n",
            "[16:16:12] [DEBUG] Face rejected: too_small\n",
            "[16:16:12] [DEBUG] Face rejected: too_small\n",
            "[16:16:12] [DEBUG] Face rejected: too_small\n",
            "[16:16:13] [DEBUG] Face rejected: too_small\n",
            "[16:16:13] [DEBUG] Face rejected: too_small\n",
            "[16:16:13] [DEBUG] Face rejected: too_small\n",
            "[16:16:13] [DEBUG] Face rejected: too_small\n",
            "[16:16:13] [DEBUG] Face rejected: too_small\n",
            "[16:16:13] [DEBUG] Face rejected: too_small\n",
            "[16:16:13] [DEBUG] Face rejected: too_small\n",
            "[16:16:13] [DEBUG] Face rejected: too_small\n",
            "[16:16:13] [DEBUG] Face rejected: too_small\n",
            "[16:16:13] [DEBUG] Face rejected: too_small\n",
            "[16:16:13] [DEBUG] Face rejected: too_small\n",
            "[16:16:13] [DEBUG] Face rejected: too_small\n",
            "[16:16:13] [DEBUG] Face rejected: too_small\n",
            "[16:16:13] [DEBUG] Face rejected: too_small\n",
            "[16:16:13] [DEBUG] Face rejected: too_small\n",
            "[16:16:13] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:14] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:15] [DEBUG] Face rejected: too_small\n",
            "[16:16:16] [DEBUG] Face rejected: too_small\n",
            "[16:16:16] [DEBUG] Face rejected: too_small\n",
            "[16:16:16] [DEBUG] Face rejected: too_small\n",
            "[16:16:16] [DEBUG] Face rejected: too_small\n",
            "[16:16:16] [DEBUG] Face rejected: too_small\n",
            "[16:16:16] [DEBUG] Face rejected: too_small\n",
            "[16:16:16] [INFO] Recognition complete. Marked 0 attendees.\n",
            "[16:16:16] [INFO] Annotated video saved to: /content/drive/MyDrive/debug_faces/annotated_output.mp4\n",
            "[16:16:16] [INFO] \n",
            "[STEP 5] EXPORTING RESULTS\n",
            "[16:16:16] [INFO]    Using: DatabaseManager.export_attendance()\n",
            "[16:16:16] [INFO] Attendance exported to /content/drive/MyDrive/attendance_report.csv\n",
            "\n",
            "--- ATTENDANCE REPORT ---\n",
            "Empty DataFrame\n",
            "Columns: [name, timestamp, confidence]\n",
            "Index: []\n",
            "[16:16:16] [INFO] \n",
            "[STEP 6] VISUALIZING TIMELINE\n",
            "[16:16:16] [INFO]    Using: matplotlib for timeline visualization\n",
            "[16:16:16] [WARNING] No attendance records to visualize\n",
            "[16:16:16] [INFO] \n",
            "============================================================\n",
            "[16:16:16] [INFO] PIPELINE COMPLETE!\n",
            "[16:16:16] [INFO] ============================================================\n",
            "\n",
            "    \n",
            "                        CLASSES SUMMARY                         \n",
            "    \n",
            "       Config               - Configuration loaded             \n",
            "       DatabaseManager      - DB initialized & populated       \n",
            "       ImageEnhancer        - Face enhancement applied         \n",
            "       FaceQualityAssessor  - Quality filtering active         \n",
            "       FaceProcessor        - RetinaFace + ArcFace used        \n",
            "       MultiClassifierMatcher - KNN/FAISS/SVM ensemble         \n",
            "       TrackerManager       - DeepSORT tracking + voting       \n",
            "    \n",
            "    \n"
          ]
        }
      ]
    }
  ]
}